\chapter{Conclusions}\label{ch:conclusions}

\lettrine{\textcolor{accent_color}{T}}{his} thesis has focused on the exploration of robotic visual navigation, specifically in the context of visual semantic navigation, and how it can be improved through the use of \acrshort{rl} methodologies.
The main objective has been to develop a new \acrshort{ros} framework that allows the integration of different algorithms and environments, as well as to explore new approaches to offline \acrshort{rl} and \acrshort{mil} for robotic visual navigation.
Concretely, the thesis has focused into studying and solving the \acrshort{objnav} problem in the real world, which consists of navigating to a specific object instance in an determined environment using visual information.
This is a challenging task since it involves a combination of several abilities, such as visual perception, semantic understanding, and navigation in complex environments.

This problem has been heavily dependent on the use of simulated environments for training and evaluation, which has limited the applicability of the developed algorithms in real-world scenarios.
However, it is not until recent years that the use of real-world data for evaluation has become more common, allowing for a better understanding of the limitations and challenges of the developed algorithms in real scenarios.
In this scenario, the thesis focuses on studying the limitations of the current approaches to robotic visual navigation in the real world, and how they can be improved through the use of new methodologies and frameworks.

This chapter summarizes the main contributions derived from the research carried on while the development of this thesis.
It also tackles the discussion and limitations of the proposed approaches, as well as the future research lines that can be explored to further improve the state of the art in robotic visual navigation.
Finally, it summarizes the scientific contributions derived from this thesis, both directly related to the main topic and side contributions that have been developed in parallel.

\section{Contributions}\label{sec:contributions}

Broadly, the thesis has contributed to the topics of \acrfull{vsn} and different algorithms for it in the context of robotic visual navigation, and how they can be improved through the use of new methodologies and frameworks.

\subsection{Contributions to the study of Visual Semantic Navigation}\label{subsec:contributions-to-visual-semantic-navigation}

The \acrshort{vsn} problem has been a challenging task in the field of robotics, and almost all the proposed solutions laid on the use of reinforcement learning methodologies.
The problem with reinforcement learning in the machine learning field is that it is a less industrialized field than others, like supervised learning or generative models.
This has lead to a diverse use of several \acrshort{RL} libraries and frameworks, which has made it difficult to compare the results of different approaches and to reproduce the results of previous works.
Also, the use of simulated environments for training and evaluation has limited the applicability of the developed algorithms in real-world scenarios.

To address these issues, this thesis has proposed two solutions: a thorough study for evaluation protocols in \acrshort{VSN} and the development of a new framework for robotic visual navigation that allows the integration of different algorithms in real environments.
The following list details the main contributions to the field of \acrshort{vsn} that have been developed during the thesis:

\begin{itemize}
    \item An intensive study of the current state of the art in \acrshort{vsn} and its limitations, which has allowed to identify the main challenges and opportunities for improvement in this field.
    The review of the literature helped to identify tantos important aspects:
        \begin{enumerate}
            \item There is a lack of standarized frameworks and protocols for training and evaluating \acrshort{vsn} algorithms, which has made it difficult to compare the results of different approaches and to reproduce the results of previous works.
            \item Almost all the proposed solutions to \acrshort{vsn} are based on simulation, and while this is a common practice in the field of robotics, it does not allow for a realistic measurement of the performance of the algorithms in the real world.
            \item Although plenty of methods have been proposed to solve the \acrshort{vsn} problem, and even some of them have been tested in real robots, there is a lack of methods developed specifically for real-world scenarios, and how to quickly adapt them to new environments.
        \end{enumerate}
    \item A new \acrshort{vsn} model that leverages CLIP~\cite{radford2021} encoders to process the visual information followed by an RNN module to output the navigation actions.
    \item An evaluation of different \acrshort{rl} techniques to deal with the sample inefficiency~\cite{Yarats2019ImprovingSE} problem of online reinforcement learning: \textit{reward shaping} and $\epsilon-greedy$~\cite{mnih2013}.
    \item The design of a new thorough experimental evaluation protocol for \acrshort{vsn} in simulation implemented via pyRIL~\cite{pyRIL} for two navigation environments: Miniworld-Maze~\cite{gym_miniworld} and Habitat~\cite{szot2021}.
    \item The release of a new \acrshort{ros} framework for deployment of \acrshort{vsn} algorithms in real robots.
    It allows the integration of different algorithms and environments and provides a standardized way to use them.
    \item The first time that two state-of-the-art \acrshort{vsn} algorithms (PIRLNav~\cite{ramrakhya2023} and VLV~\cite{chang2020}) have been evaluated in real robots, which has allowed to identify the main challenges and limitations of the current approaches in real-world scenarios.
    \item A new experimental evaluation for \acrshort{vsn} algorithms in the real world using the proposed \acrshort{ros} framework, which has allowed to measure the performance of the algorithms in real-world scenarios and to identify the main challenges and limitations of the current approaches.
\end{itemize}

\subsection{Contributions to the development of new algorithms for Visual Semantic Navigation}\label{subsec:contributions-to-new-algorithms-for-visual-semantic-navigation}

The thesis has also contributed to the development of new algorithms for \acrshort{vsn} that can be used in real-world scenarios.
While these algorithms resemble the same problem formulation used for \acrshort{rl}, they are not based on classical \acrshort{rl} methodologies but rather on offline reinforcement learning and meta-imitation learning.
These approaches aim to go \textit{beyond} the current \acrshort{rl} methodologies and try to provide a foundation for future research in algorithms that are meant to overcome the limitations of \acrshort{rl} in the real world.

Specifically, the following contributions have been made:

\begin{itemize}
    \item A new simplified experimental evaluation protocol for HM3D~\cite{ramakrishnan2021} dataset, based on five different setups that increase the complexity of the navigation task.
    This allows for faster training and evaluation of algorithms.
    \item A new approach to \acrshort{vsn} based on offline reinforcement learning called \textbf{Off}line Visual Semantic \textbf{Nav}igation (OffNav).
    This approach allows training \acrshort{vsn} algorithms using offline data, which can be collected in real-world or simulated scenarios.
    This algorithm is based on the Implicit Q-Learning (IQL)~\cite{kostrikov2022offline} algorithm, but adapted to decentralized distributed training and evaluation.
    The model is able to generalize to unseen environments and in the most challenging setup it outperforms the state-of-the-art PIRLNav~\cite{ramrakhya2023} algorithm.
    \item A novel model for \acrshort{vsn} based on meta-imitation learning called \textbf{Meta} Imitation Learning for Visual Semantic \textbf{Nav}igation (MetaNav).
    This approach allows training navigation policies using pre-recorded demonstrations in a meta-learning fashion.
    The model is an adaptation from~\cite{finnOneShotVisualImitation2017} to work in the \objnav setting.
\end{itemize}

\section{Discussion and Limitations}\label{sec:discussion-and-limitations}

As any research works, this thesis provides more questions than answers.
Besides the contributions listed in the previous sections, there are several elements that could be addressed to improve the work here done.
Although some of them represent limitations and challenges that have been identified during the development of this thesis, there are others than resemble all the possibilities unexplored.
Some of these elements are listed below:
\begin{itemize}
    \item The \acrshort{vsn} models employed alongside this thesis are always based on the same principle: a visual feature extractor (typically CNNs, but not limited to) plus RNNs to output action distributions.
    This is a good starting point and has been identified as a strong baseline for navigation models~\cite{wijmans2020}.
    However, navigation could be improved by using more recent architectures, such as transformers~\cite{Vaswani2017AttentionIA} or diffusion~\cite{pmlr-v37-sohl-dickstein15} models, which have shown to be also effective in embodied \acrshort{ai} tasks~\cite{Shah2023ViNTAF, ren2025prior}.
    \item All the proposed algorithms and analysis performed for \acrshort{vsn} are based on the same task formulation: navigating to a specific object instance in an environment, known as \acrshort{objnav}.
    While this is still a challenging task, specially in the real world and dynamic environments, there are other tasks that could be explored.
    As expressed in chapter~\ref{ch:introduction}, if we want a robot to be able to interact with the environment as humans, it has to be able to perform more complex tasks than just navigating to a specific object instance.
    There are plenty of tasks that could be explored.
    Some of them, but not all are: vision and language navigation~\cite{Anderson2017VisionandLanguageNI}, in which and agent has to navigate to a specific location in an environment based on a natural language instruction; HAZARD navigation~\cite{Zhou2024HAZARDCE}, in which an agent has to rescue a given set of objects from disasters such as fires, floods, and winds; Open-Vocabulary Mobile Manipulation~\cite{homerobotovmm, homerobotovmmchallenge2023}, which is the problem of picking any object in any unseen environment, and placing it in a commanded location; or even more dynamic tasks such as Social Navigation~\cite{puig2024habitat}, a set of tasks that involve cooperation between multiple agents or agents and humans.
    Some of these tasks can be about navigating in an environment while avoiding moving humans, or even rearranging objects in coordination with a human agent.
    \item While this thesis proposes two new algorithms for \acrshort{vsn} based on offline reinforcement learning and meta-imitation learning in chapter~\ref{ch:beyond-rl}, these algorithms struggle to outperform the state-of-the-art algorithms in the most challenging setups.
    As pointed out in section~\ref{sec:training-problems}, both algorithms suffer from an inability to be trained in the full \acrshort{hm3d} dataset train split.
    While further research is needed to understand the limitations of these algorithms, the experimental evidence suggests that the heavy modifications made to the original algorithms made them actually less effective than the original ones.
    \item As the algorithms from chapter~\ref{ch:beyond-rl} showed bad performance in the most challenging setups, they were not tested in real robots.
    However, tests on real robots are crucial to understand the limitations of the algorithms and how they can be improved, and they could have shown crucial insights on how to improve the algorithms.
    \item All the algorithms studied or proposed in this thesis are based on robot learning.
    All of them have at least one component trained using reinforcement learning or imitation learning.
    However, these algorithms do not represent the whole space of algorithms that can be used for \acrshort{vsn}, and in more general any robotic task.
    Moreover, these other algorithms can be used in conjunction with the proposed algorithms to improve their performance.
    Nonetheless, this thesis is focused on learning algorithms, and other methods such as planning, control, or even classical computer vision methods are out of the scope.
\end{itemize}

\section{Future Research Lines}\label{sec:future-work}

Despite much effort has been put into the development of this thesis, the ultimate goal of achieving a fully autonomous robot that can navigate and interact with the environment as humans do is still far from being achieved.
Apart from all the required research that has to be made in order to fulfill the limitations and challenges listed in the previous section, there are several research lines that can be explored to further improve the state of the art in robotic visual navigation.

First of all, despite the algorithms presented in chapter~\ref{ch:beyond-rl} are meant to bridge the gab between simulation and real-world scenarios, they have not been tested in real robots.
By leveraging on the framework ROS4VSN proposed in chapter~\ref{ch:ros4vsn:-enable-real-world-robotic-visual-semantic-navigation}, these algorithms can be easily deployed in real robots and tested in real-world.
This is the most immediate research line that can be explored, as it will reflect how these algorithms perform in real-world scenarios and how they can be improved.
Nevertheless, developing algorithms in simulation and testing them in real robots is only the first step, even if they are meant to be used in real-world scenarios.
The problem is that normal simulation time for end-to-end reinforcement learning algorithms surpasses that of a human lifetime.
However, typically, humans are able to interact with an environment as soon as they reach their first year of life.
This difference in learning time is due to the sample inefficiency of reinforcement learning algorithms, which is a well-known problem in the field.
Making algorithms that can learn from real-world data in the same time as humans (or even faster) is a challenging task, but it is crucial to achieve fully autonomous robots.

Second, in the particular case of MetaNav, proposed in section~\ref{sec:meta-imitation-learning}, there is one immediate research line that can be explored.
Instead of using meta-imitation learning via a gradient-based approach, task-inference methods~\cite{Beck_2025, rakelly2019} can be used.
These methods allow conditioning the policies to task representations, which can be meta-learned from the training tasks.
This would allow for the main components of the model to be trained in the same fashion as the original algorithm, but with the added contextual information provided by the task representations.
In the particular case of \acrshort{objnav}, these task representation could be inferred by some geometrical distribution of the object instances in the environment, such as the distance to the goal object, or even the visual features of the object.

Finally, this since thesis has focused on the \acrshort{objnav} problem, all the algorithms and approaches proposed and analyzed only use visual information to navigate in an environment.
However, there are other sources of information that can be used to improve the performance of the algorithms.
For instance, the use of audio signals~\cite{Kondoh2023MultigoalAN} can be used to improve the performance of the algorithms in real-world scenarios, as it can provide additional information about the environment and the objects in it.
Another example is the use of tactile sensors~\cite{Ota2023TactileEO}, which can provide additional information about the objects in the environment and can be used to improve the performance of the algorithms in real-world scenarios.

These are just some examples of the many research lines that can be explored to further improve the state of the art in robotic visual navigation.
Fortunately, the field of robotics is constantly evolving, and new approaches and methodologies are being developed every day.

\section{Scientific Contributions}\label{sec:final-remarks}

During the development of this thesis, there have been contributions to several topics.
Most of them are directly related to the main topic of the thesis.
However, it has also been possible to contribute to other topics that, although not directly related to the thesis, have been developed in parallel.
These have come from side projects or collaborations with other research groups and have contributed to the development of this thesis.
All of them are summarized in the following subsections.

\subsection{Contributions directly related to the thesis}\label{subsec:contributions-directly-related-to-the-thesis}

\begin{itemize}
    \item \cvpub{\textbf{Gutiérrez-Alvarez C.}, Ríos-Navarro P., Flor-Rodríguez-Rabadán R., Acevedo-Rodríguez F.J., López-Sastre R.J., \textit{Visual Semantic Navigation with Real Robots}, in Applied Intelligence, 2024.}.
    See paper \href{https://link.springer.com/article/10.1007/s10489-024-06115-4}{here}.
    \item \textbf{Gutiérrez-Alvarez C.}, Acevedo-Rodríguez F.J., López-Sastre R.J., Kanezaki A., OffNav: \textit{Offline Reinforcement Learning for Visual Semantic Navigation}, in ICRA Human-aligned Reinforcement Learning for Autonomous Agents and Robots Workshop, 2024.
    See paper \href{https://harlworkshop.github.io/2024/submission_10.pdf}{here}.
    \item \textbf{Gutiérrez-Alvarez C.}, Ríos-Navarro P., Flor-Rodríguez-Rabadán R., Acevedo-Rodríguez F.J., López-Sastre R.J., \textit{Evaluation of Visual Semantic Navigation Models in Real Robots}, in IROS Late Breaking Results, 2023.
    See abstract \href{http://monke.es/media/gutierrez-alvarez-evaluation-of-vsn-models.pdf}{here}.
    \item \textbf{Gutiérrez-Alvarez C.}, Hernández García S, Nasri N, Cuesta-Infante Alfredo, López-Sastre RJ, \textit{Towards Clear Evaluation of Robotic Visual Semantic Navigation}, in ICARA, 2023.
    See paper \href{https://ieeexplore.ieee.org/abstract/document/10125866/}{here}.
    \item \textit{Participation in the project \textbf{NAVIGATOR-D} (PID2023-148310OB-I00)}, funded by the Spanish Ministry of Science and Innovation.
    \item \textit{Participation in the project \textbf{AIRPLANE} (PID2019-104323RB-C31)}, funded by the Spanish Ministry of Science and Innovation.
\end{itemize}

\subsection{Side contributions}\label{subsec:side-contributions}

\begin{itemize}
    \item Flor-Rodríguez-Rabadán R., \textbf{Gutiérrez-Álvarez C.}, Acevedo-Rodríguez F.J., Lafuente-Arroyo S., López-Sastre R.J., \textit{SEMNAV: A Semantic Segmentation-Driven Approach to Visual Semantic Navigation}, in ArXiv, 2025.
    See paper \href{https://arxiv.org/abs/2506.01418}{here}.
    \item Blanco-Fernández E., \textbf{Gutiérrez-Alvarez C.}, Nasri N., Maldonado-Bascón S., López-Sastre R.J., \textit{Live Video Captioning}, in Multimedia Tools and Applications, 2025.
    See paper \href{https://link.springer.com/article/10.1007/s11042-025-20908-w}{here}.
    \item Nasri N, \textbf{Gutiérrez-Álvarez C.}, López-Sastre RJ, Lafuente-Arroyo S., Maldonado-Bascón S. \textit{Realistic Continual Learning Approach using Pre-trained Models}, in ArXiv 2024.
    See paper \href{https://arxiv.org/abs/2404.07729}{here}.
    \item Lafuente-Arroyo S., Maldonado-Bascón S., Delgado-Mena D., \textbf{Gutiérrez-Alvarez C.}, Acevedo-Rodríguez F.J., \textit{Multisensory Integration for Topological Indoor Localization of Mobile Robots in Complex Symmetrical Environments}, in Expert Systems with Applications, 2023.
    See paper \href{https://www.sciencedirect.com/science/article/pii/S0957417423030634}{here}.
    \item Nasri N, López-Sastre RJ, Pacheco-da-Costa S, Fernández-Munilla I, \textbf{Gutiérrez-Álvarez C.}, Pousada-García T, Acevedo-Rodríguez FJ, Maldonado-Bascón S. \textit{Assistive Robot with an \acrshort{ai}-Based Application for the Reinforcement of Activities of Daily Living: Technical Validation with Users Affected by Neurodevelopmental Disorders}, in Applied Sciences, 2022.
    See paper \href{https://www.mdpi.com/2076-3417/12/19/9566}{here}.
\end{itemize}